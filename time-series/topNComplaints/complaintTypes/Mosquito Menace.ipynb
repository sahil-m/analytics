{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadData <- function(dataFolder) {\n",
    "    files <- list.files(dataFolder)\n",
    "    data <- list()\n",
    "    for(file in files) {    \n",
    "        df <- read.csv(paste0(dataFolder, \"/\", file), stringsAsFactors=F)    \n",
    "        minYear <- min(df$Year)\n",
    "        complaintType <- substr(file,1,(nchar(file))-4)    \n",
    "        tsObject <- ts(df$Complaints, start=c(minYear, 1), frequency = 12)\n",
    "        data[[complaintType]] <- tsObject\n",
    "    }\n",
    "    data\n",
    "}\n",
    "data <- loadData(\"../../data/topNComplaints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series <- data[[\"Mosquito menace \"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsdisplay(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data before 2012 are too few to consider\n",
    "series <- window(series, start=c(2012, 1), end=c(2016, 6))\n",
    "tsdisplay(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up data \n",
    "\n",
    "This data looks like it has 3 outliers- one in 2013-2014 and two near 2015. Let's take a look at the 'cleaned' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(series, col=\"red\", lty=2)\n",
    "lines(tsclean(series), lty=1)\n",
    "legend(\"topright\", col=c(\"red\", \"black\"), lty=c(2,1), legend=c(\"Original\", \"Cleaned\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the cleaned series. For initial analysis we will use both series, one cleaned, and other other left as is. For fitting time series models, we will stick to the cleaned series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series.cleaned <- tsclean(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition\n",
    "\n",
    "The series does look like it has a seasonal component - let's take a look at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(stl(series, s.window=\"periodic\"))\n",
    "# those two spikes in the seasonal component is pronounced probably due to the outliers, so for estimating \n",
    "# the seasonal component it would be better to look at the cleaned adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's fiddle with the s.window parameter\n",
    "plot(stl(series, s.window=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now take a look at the cleaned series\n",
    "plot(stl(series.cleaned, s.window=6))\n",
    "# this is much more regular, especially the seasonal component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's take a look at which month this series peaks\n",
    "seasonal <- stl(series.cleaned, s.window=6)$time.series[, 1] # change s.window\n",
    "plot(seasonal, col=\"grey\")\n",
    "month <- 11 # change this to month you want\n",
    "for(i in 2012:2016) {    \n",
    "    abline(v=(month-1)/12 + i, lty=2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this series looks like it fits the data well - since the seasonal component does seem to increase as time progresses\n",
    "# let's set s.window = 6\n",
    "stl.fit <- stl(series.cleaned, s.window=6)\n",
    "series.adj <- seasadj(stl.fit)\n",
    "tsdisplay(series.adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting\n",
    "### ARIMA models - estimating p, d, q\n",
    "\n",
    "First, let us estimate $d$. This is done by looking at the ACF of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Acf(series.adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the above series is a classic example of a series that requires a diff of order 1, \n",
    "# so let's try that out and take a look at the Acf to see if it is overdifferenced\n",
    "tsdisplay(diff(series.adj, lag=1, differences = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# looks like the series has a strong, positive ACF at lag 12\n",
    "# it's possible that this series still has a seasonal component\n",
    "# let's also look at d=2\n",
    "tsdisplay(diff(series, lag = 1, differences = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take a look at standard-deviation\n",
    "sd.0 <- sd(series.adj)\n",
    "sd.1 <- sd(diff(series.adj, differences = 1))\n",
    "sd.2 <- sd(diff(series.adj, differences = 2))\n",
    "print(paste0(\"SD with d = 0: \", sd.0, \", SD with d = 1: \", sd.1, \", SD with d = 2: \", sd.2))\n",
    "# in terms of sd, d=1 is a better fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndiffs(series.adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series.diff <- diff(series.adj, lag=1, differences = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(series.diff, col=\"grey\")\n",
    "# a 2x4 MA\n",
    "lines(ma(ma(series.diff, order=2), order=4))\n",
    "abline(mean(series.diff), 0, col=\"blue\", lty=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to estimate p and q. To do this, we take a look at the PACF of the data. Note that this analysis is done on the differenced data. If we decide to fit a model with d=0, then we need to perform this analysis for the un-differenced data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let d=0 first\n",
    "# looks like a AR(1), MA(12)\n",
    "Pacf(series.adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's try with d=1\n",
    "# looks like AR(11), MA(4) process\n",
    "Pacf(series.diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building candidate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelArima <- function(series, order, h, testData = NULL) {\n",
    "    fit <- Arima(series, order=order)\n",
    "    print(summary(fit))\n",
    "    predictions <- forecast(fit, h)\n",
    "    # compute max and min y\n",
    "    min.yvalue <- min(min(series), min(testData))\n",
    "    max.yvalue <- max(max(series), max(testData))\n",
    "    \n",
    "    plot(predictions, ylim=c(min.yvalue, max.yvalue))\n",
    "    if(!is.null(testData)) {\n",
    "        lines(testData, col=\"red\", lty=2)\n",
    "        print(accuracy(predictions, testData))\n",
    "    }\n",
    "    # check if residuals looklike white noise\n",
    "    Acf(residuals(fit), main=\"Residuals\")\n",
    "    # portmantaeu test\n",
    "    print(Box.test(residuals(fit), lag=24, fitdf=4, type=\"Ljung\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the series into a test and a train set\n",
    "series.train <- window(series.adj, end=c(2015, 6))\n",
    "series.test <- window(series.adj, start=c(2015, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with d=0, p=3, q=6\n",
    "modelArima(series.train, c(1, 0, 12), length(series.test), series.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with d=1, p=0, q=2\n",
    "modelArima(series.train, c(11, 1, 5), length(series.test), series.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mosquito menace\n",
    "series\n",
    "series <- window(series, start = c(2012,4), end = c(2016,6))\n",
    "stl.fit <- stl(series, s.window=8)\n",
    "series.adj <- seasadj(stl.fit)\n",
    "seasonal <- stl.fit$time.series[, 1]\n",
    "seasonal_train <- stl(window(series, end = c(2015,6)), s.window = 8)[[1]][,1]\n",
    "#tsdisplay(series.adj)\n",
    "plot(seasonal)\n",
    "plot(seasonal_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stl.fit <- stl(series, s.window=\"periodic\")\n",
    "series.adj <- seasadj(stl.fit)\n",
    "seasonal <- stl.fit$time.series[, 1]\n",
    "seasonal_train <- stl(window(series, end = c(2015,6)), s.window = \"periodic\")[[1]][,1]\n",
    "#tsdisplay(series.adj)\n",
    "plot(seasonal)\n",
    "plot(seasonal_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seasonal\n",
    "seasonal_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Three peaks are observed in both the training and overall data sets, but the difference is the amplitude in each of them. It is noticed that the peaks in november and drops in April-May are almost the small. But there are variations in some other months, yet the pattern of seasonality looks more or less the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function for finding the average of seasonal components\n",
    "period_stat <- function(ts_data_in, type = 1, start_value, years){\n",
    "#type 1: sum\n",
    "#type 2: mean\n",
    "\n",
    "freq <- frequency(ts_data_in)\n",
    "len <- length(ts_data_in)\n",
    "\n",
    "freq_vector <- numeric(0)\n",
    "freq_sum <- numeric(0)\n",
    "vec <- numeric(0)\n",
    "sum_vec <- numeric(0)\n",
    "\n",
    "start_val <- start(ts_data_in)\n",
    "\n",
    "ts_data_in <- c(rep(NA,start_val[2] - 1),ts_data_in)\n",
    "\n",
    "max_limit <- ceiling(len/freq)\n",
    "    for(i in 1:max_limit){\n",
    "    \n",
    "    vec <- ts_data_in[(((i-1)*freq)+1):(((i-1)*freq)+freq)]\n",
    "    freq_vector <- as.numeric(!is.na(vec))\n",
    "    vec[is.na(vec)] <- 0\n",
    "    \n",
    "    if(i == 1){\n",
    "    sum_vec <- vec\n",
    "    freq_sum <- freq_vector\n",
    "    }else{\n",
    "    sum_vec <- sum_vec + vec\n",
    "    freq_sum <- freq_sum + freq_vector\n",
    "    }\n",
    "    }\n",
    "\n",
    "final_ts <- numeric(0)\n",
    "if(type == 1)\n",
    "{\n",
    "    final_ts <- sum_vec\n",
    "}else if(type == 2) {\n",
    "\n",
    "    final_ts <- (sum_vec/freq_sum)\n",
    "} else {\n",
    "    stop(\"Invalid type\")\n",
    "}\n",
    "\n",
    "\n",
    "return(ts(rep(final_ts,years),frequency = freq, start = start_value ))\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adjust the negative values in the ts data\n",
    "es_series <- series.adj\n",
    "min_ts_value <- min(es_series)\n",
    "\n",
    "bias_value <- (-1*min_ts_value) + 1\n",
    "ES_series <- es_series+ bias_value\n",
    "#plot(ES_series)\n",
    "ES_series\n",
    "\n",
    "train_data <- window(ES_series, end=c(2015, 6))\n",
    "test_data <- window(ES_series, start=c(2015, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting the mean value from the seasonal components for the data set and not for the training set alone.\n",
    "#Need to adjust based on the input from Suchana.\n",
    "\n",
    "seasonal_mean <- period_stat(seasonal,2,c(2012,1),years = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preprocessing data. Removing 0 from the data\n",
    "train_data[train_data==0]=0.01 \n",
    "\n",
    "#Fitting a model with ets function\n",
    "\n",
    "ets1 = ets(train_data)\n",
    "summary(ets1)\n",
    "plot(forecast(ets1))\n",
    "lines(test_data, col = \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ljung Box test - One of the checks to perform stationarity of TS data\n",
    "Box.test(ets1$residuals, lag = 20, type = \"Ljung-Box\")\n",
    "p_value <- Box.test(ets1$residuals, lag = 20, type = \"Ljung-Box\")$p.value\n",
    "Acf(ets1$residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_types = c(\"ANN\",\"AAN\",\"AAA\",\"ANA\",\"MNN\",\"MAN\",\"MNA\",\"MAA\",\"MMN\",\"MNM\",\"MMM\",\"MAM\")\n",
    "forecast_values = 12\n",
    "# For eg: AAA -> additive level, additive trend and additive seasonality\n",
    "# ANN -> No trend or seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_fit <- list()\n",
    "test_models <- list()\n",
    "\n",
    "print(\"Fitting various models: \")\n",
    "for (bool in c(TRUE,FALSE)){\n",
    "    for (model_type in all_types){\n",
    "\n",
    "        if(bool & substr(model_type,2,2)==\"N\"){\n",
    "            next\n",
    "        }\n",
    "    test_model = ets(train_data, model = model_type,damped = bool)\n",
    "    #Box.test(test_model$residuals, lag = 20, type = \"Ljung-Box\")$p.value\n",
    "    all_fit[[paste0(\"ETS Model: \",model_type,\", Damped: \",bool)]][1] <- accuracy(test_data, forecast.ets(test_model,h=forecast_values)$mean )[5]\n",
    "    all_fit[[paste0(\"ETS Model: \",model_type,\", Damped: \",bool)]][2] <- 100*(Box.test(test_model$residuals, lag = 20, type = \"Ljung-Box\")$p.value)\n",
    "    \n",
    "        test_models[[paste0(\"ETS Model: \",model_type,\", Damped: \",bool)]] <- test_model\n",
    "\n",
    "        print(test_model$method)\n",
    "        print(accuracy(test_data, forecast.ets(test_model,h=forecast_values)$mean )[5])\n",
    "        print(\"\")\n",
    "\n",
    "        #Excluding the models which has auto correlated residuals @ 10% significance level\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding the best fit\n",
    "proper_models <- all_fit\n",
    "    if(length(proper_models)==0){\n",
    "        print(\"None of the model satisfies - Ljung-Box test; Model with least 3 p values taken\")\n",
    "        p_values <- sapply(all_fit, function(x)x[2])\n",
    "        proper_models <- all_fit[order(p_values)][1:3]\n",
    "    }\n",
    "\n",
    "    best_mape <- min(sapply(proper_models,function(x)x[1]))\n",
    "    best_model <- names(which.min(sapply(proper_models,function(x)x[1])))\n",
    "\n",
    "    print(paste0(\"Complaint: \",names(TS_data)))\n",
    "    print(paste0(\"Best Model:\",best_model))\n",
    "    print(paste0(\"Best Mape: \",best_mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding top n fits\n",
    "top_models <- c()\n",
    "Top_n <- 3\n",
    "\n",
    "if(length(proper_models)<3){Top_n <- length(proper_models)}\n",
    "\n",
    "top_mape_val <- proper_models[order(sapply(proper_models, function(x)x[1]))][1:Top_n]\n",
    "top_models <- names(top_mape_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_mape_val\n",
    "seasonal_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(ES_series,col = \"black\")\n",
    "lines(test_data, col = \"blue\")\n",
    "lines(forecast.ets(test_models[[top_models[1]]],h=12)$mean, col = \"red\") #Top model\n",
    "lines(forecast.ets(test_models[[top_models[2]]],h=12)$mean, col = \"green\") #Top second model\n",
    "lines(forecast.ets(test_models[[top_models[3]]],h=12)$mean, col = \"yellow\") #Top third model\n",
    "\n",
    "#Observation: Unusual peak at December'15. To check if it is an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting back the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adding the bias value which was added to overcome the negative values\n",
    "ES_series_bias <- ES_series - bias_value\n",
    "test_series_bias <- test_data - bias_value\n",
    "forecast1_bias <- forecast.ets(test_models[[top_models[1]]],h=12)$mean - bias_value\n",
    "forecast2_bias <- forecast.ets(test_models[[top_models[2]]],h=12)$mean - bias_value\n",
    "forecast3_bias <- forecast.ets(test_models[[top_models[3]]],h=12)$mean - bias_value\n",
    "\n",
    "#Adding back the seasonal value from stl decomposition\n",
    "ES_value <- ES_series_bias + seasonal\n",
    "test_series <- test_series_bias + seasonal\n",
    "\n",
    "forecast1 <- forecast1_bias + seasonal_mean\n",
    "forecast2 <- forecast2_bias + seasonal_mean\n",
    "forecast3 <- forecast3_bias + seasonal_mean\n",
    "\n",
    "\n",
    "accuracy(test_models[[top_models[1]]])\n",
    "accuracy(test_models[[top_models[2]]])\n",
    "accuracy(test_models[[top_models[3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Checking the MAPE values with original data\n",
    "print(paste0(\"Top model: \", top_models[1]))\n",
    "accuracy(forecast1,test_series)\n",
    "print(paste0(\"Top model: \", top_models[2]))\n",
    "accuracy(forecast2,test_series)\n",
    "print(paste0(\"Top model: \", top_models[3]))\n",
    "accuracy(forecast3,test_series)\n",
    "\n",
    "#accuracy(test_data, forecast.ets(test_models[[top_models[3]]],h=12)$mean )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ljung Box test - One of the checks to perform stationarity of TS data\n",
    "#Top model\n",
    "print(top_models[1])\n",
    "Box.test(test_models[[top_models[1]]]$residuals, lag = 20, type = \"Ljung-Box\")\n",
    "p_value <- Box.test(test_models[[top_models[1]]]$residuals, lag = 20, type = \"Ljung-Box\")\n",
    "Acf(test_models[[top_models[1]]]$residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ljung Box test - One of the checks to perform stationarity of TS data\n",
    "#Top second model\n",
    "print(top_models[2])\n",
    "Box.test(test_models[[top_models[2]]]$residuals, lag = 20, type = \"Ljung-Box\")\n",
    "p_value <- Box.test(test_models[[top_models[2]]]$residuals, lag = 20, type = \"Ljung-Box\")\n",
    "Acf(test_models[[top_models[2]]]$residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ljung Box test - One of the checks to perform stationarity of TS data\n",
    "#Top Third model\n",
    "print(top_models[3])\n",
    "Box.test(test_models[[top_models[3]]]$residuals, lag = 20, type = \"Ljung-Box\")\n",
    "p_value <- Box.test(test_models[[top_models[3]]]$residuals, lag = 20, type = \"Ljung-Box\")\n",
    "Acf(test_models[[top_models[3]]]$residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual plot output: From the plot, all the errors seem to be random and there appears to be no much autocorrelation among the errors, confirming that the data is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(ES_value,col = \"black\") #Original data set\n",
    "lines(test_series, col = \"blue\") #Original test data\n",
    "lines(test_series_bias + seasonal_mean, col = \"black\") #Deseasonlised data with average seasonal component applied\n",
    "lines(forecast1, col = \"red\") #Top model\n",
    "lines(forecast2, col = \"green\") #Top second model\n",
    "lines(forecast3, col = \"yellow\") #Top third model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation: The predicted forecast, after applying the seasonal component overpredicts the complaint for one of the months (due to the pattern of the seasonal component). So either the seasonality is absent in the actual data for that particular month or the seasonal component derived is not accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
